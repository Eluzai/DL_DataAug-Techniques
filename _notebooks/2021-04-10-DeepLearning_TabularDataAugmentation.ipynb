{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd05949c72ebbe418b9cc797ad236269fe4db8de7202334b5e81059047e16359c40",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Learning for tabular data augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### How to use a variational Autoencoder to augment tabular data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "When it comes to DeepLearning, the more data we have the better the chances are to get a great performing model. In fields like image recognition research has already came up with quite a few clever ideas how to use the existing data to create more data out of it. This is called data augmentation. \n",
    "\n",
    "However, when we look at Deep Learning in the tabular data context, there are still many concepts missing. What I would like to show in this blogpost is a way to augment tabular data, what we could use in order to train a DeepLearning Model on more tabular data, or which can be used to create data of underrepresented classes. \n",
    "\n",
    "I want to show graphically how this newly created data is sampled from the distribution of the underlying data and hence how this data can help to make better Deep Learning models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "I've already created a small library, which I called deep_tabular_augmentation. In here I've created a class, which handles all of the tabular data augmentation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import deep_tabular_augmentation as dta\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "source": [
    "So first, we need to get some data. Here, I've got some data on the infamous wine-dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0     1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1     1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2     1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3     1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4     1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "\n",
       "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                  0.39     1.82       4.32  1.04  2.93      735  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Wine</th>\n      <th>Alcohol</th>\n      <th>Malic.acid</th>\n      <th>Ash</th>\n      <th>Acl</th>\n      <th>Mg</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid.phenols</th>\n      <th>Proanth</th>\n      <th>Color.int</th>\n      <th>Hue</th>\n      <th>OD</th>\n      <th>Proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_PATH = 'data/wine.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=',')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns"
   ]
  },
  {
   "source": [
    "We then build a DataLoader, in which we also standardize our data. We save the scaler in our dataset to make use of it later, when we invert the scaling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_standardize_data(path):\n",
    "    # read in from csv\n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    # replace nan with -99\n",
    "    df = df.fillna(-99)\n",
    "    df = df.values.reshape(-1, df.shape[1]).astype('float32')\n",
    "    # randomly split\n",
    "    X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "    # standardize values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)   \n",
    "    return X_train, X_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class DataBuilder(Dataset):\n",
    "    def __init__(self, path, train=True):\n",
    "        self.X_train, self.X_test, self.standardizer = load_and_standardize_data(DATA_PATH)\n",
    "        if train:\n",
    "            self.x = torch.from_numpy(self.X_train)\n",
    "            self.len=self.x.shape[0]\n",
    "        else:\n",
    "            self.x = torch.from_numpy(self.X_test)\n",
    "            self.len=self.x.shape[0]\n",
    "        del self.X_train\n",
    "        del self.X_test \n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_set=DataBuilder(DATA_PATH, train=True)\n",
    "testdata_set=DataBuilder(DATA_PATH, train=False)\n",
    "\n",
    "trainloader=DataLoader(dataset=traindata_set,batch_size=1024)\n",
    "testloader=DataLoader(dataset=testdata_set,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([124, 14]), torch.Size([54, 14]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "trainloader.dataset.x.shape, testloader.dataset.x.shape"
   ]
  },
  {
   "source": [
    "We've build our train and test datasets, and with the help of DataLoaders we also turned them into tensors. So, let's use deep_tabular_augmentation now. The class needs seven inputs: trainloader, testloader, device on which to run the traning, the input dimension (in this case: 14), and how many nodes the first and second hidden layers should have. Finally, we can also specify the number of latent factors. These latent factors will contain all the condensed information, meaning that we can use these latent factors to recreate the original 14 input dimensions (e.g. our data)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = traindata_set.x.shape[1]\n",
    "H = 50\n",
    "H2 = 12\n",
    "\n",
    "autoenc_model = dta.AutoencoderModel(trainloader, testloader, device, D_in, H, H2, latent_dim=3)"
   ]
  },
  {
   "source": [
    "After we've successfully initiated our model, let's train it and call the trained model \"autoenc_model_fit\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====> Epoch: 200 Average training loss: 11.3281\n",
      "====> Epoch: 200 Average test loss: 11.4239\n",
      "====> Epoch: 400 Average training loss: 9.7651\n",
      "====> Epoch: 400 Average test loss: 10.3157\n",
      "====> Epoch: 600 Average training loss: 9.1283\n",
      "====> Epoch: 600 Average test loss: 10.5291\n"
     ]
    }
   ],
   "source": [
    "autoenc_model_fit = autoenc_model.fit(epochs=600)"
   ]
  },
  {
   "source": [
    "Now, all we need is to create some fake data based on the trained model. How this works is the following: we know the learned parameters for the mean and the variance of our latent factors. Then, we use a normal distribution with the mean and variance of each of the latent factors to sample a value for latent factor 1,2 and 3 (because we've got three latent facots in this case). These generated starting points for our latent factors are then used to inflate towards the 14 real input variables. Let's see how it's done:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Wine    Alcohol  Malic.acid       Ash        Acl          Mg   Phenols  \\\n",
       "0     2  12.493084    2.045130  2.237029  18.645376  101.227913  2.366858   \n",
       "1     2  12.388008    2.028943  2.237992  19.671783   93.292801  2.290553   \n",
       "2     2  12.863456    2.061298  2.315192  18.529932  104.701004  2.480082   \n",
       "3     2  12.315710    2.164225  2.261593  20.433725   91.778603  2.019248   \n",
       "4     2  12.562940    2.135798  2.234170  19.034275  101.889763  2.421708   \n",
       "\n",
       "   Flavanoids  Nonflavanoid.phenols   Proanth  Color.int       Hue        OD  \\\n",
       "0    2.039845              0.310666  1.780123   3.824865  1.053821  2.959614   \n",
       "1    2.102422              0.337810  1.582847   3.545685  1.047288  2.853665   \n",
       "2    2.273354              0.298898  1.788156   4.134489  1.071253  2.954578   \n",
       "3    1.704518              0.383477  1.496545   3.532443  0.991632  2.591641   \n",
       "4    2.133960              0.296481  1.818705   3.890027  1.052557  2.903332   \n",
       "\n",
       "      Proline  \n",
       "0  614.468567  \n",
       "1  574.657776  \n",
       "2  788.806580  \n",
       "3  531.966309  \n",
       "4  662.883545  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Wine</th>\n      <th>Alcohol</th>\n      <th>Malic.acid</th>\n      <th>Ash</th>\n      <th>Acl</th>\n      <th>Mg</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid.phenols</th>\n      <th>Proanth</th>\n      <th>Color.int</th>\n      <th>Hue</th>\n      <th>OD</th>\n      <th>Proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>12.493084</td>\n      <td>2.045130</td>\n      <td>2.237029</td>\n      <td>18.645376</td>\n      <td>101.227913</td>\n      <td>2.366858</td>\n      <td>2.039845</td>\n      <td>0.310666</td>\n      <td>1.780123</td>\n      <td>3.824865</td>\n      <td>1.053821</td>\n      <td>2.959614</td>\n      <td>614.468567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>12.388008</td>\n      <td>2.028943</td>\n      <td>2.237992</td>\n      <td>19.671783</td>\n      <td>93.292801</td>\n      <td>2.290553</td>\n      <td>2.102422</td>\n      <td>0.337810</td>\n      <td>1.582847</td>\n      <td>3.545685</td>\n      <td>1.047288</td>\n      <td>2.853665</td>\n      <td>574.657776</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>12.863456</td>\n      <td>2.061298</td>\n      <td>2.315192</td>\n      <td>18.529932</td>\n      <td>104.701004</td>\n      <td>2.480082</td>\n      <td>2.273354</td>\n      <td>0.298898</td>\n      <td>1.788156</td>\n      <td>4.134489</td>\n      <td>1.071253</td>\n      <td>2.954578</td>\n      <td>788.806580</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>12.315710</td>\n      <td>2.164225</td>\n      <td>2.261593</td>\n      <td>20.433725</td>\n      <td>91.778603</td>\n      <td>2.019248</td>\n      <td>1.704518</td>\n      <td>0.383477</td>\n      <td>1.496545</td>\n      <td>3.532443</td>\n      <td>0.991632</td>\n      <td>2.591641</td>\n      <td>531.966309</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>12.562940</td>\n      <td>2.135798</td>\n      <td>2.234170</td>\n      <td>19.034275</td>\n      <td>101.889763</td>\n      <td>2.421708</td>\n      <td>2.133960</td>\n      <td>0.296481</td>\n      <td>1.818705</td>\n      <td>3.890027</td>\n      <td>1.052557</td>\n      <td>2.903332</td>\n      <td>662.883545</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "scaler = trainloader.dataset.standardizer\n",
    "df_fake = autoenc_model_fit.predict(no_samples=500, scaler=scaler, cols=cols)\n",
    "df_fake['Wine'] = np.round(df_fake['Wine']).astype(int)\n",
    "df_fake['Wine'] = np.where(df_fake['Wine']<1, 1, df_fake['Wine'])\n",
    "df_fake['Wine'] = np.where(df_fake['Wine']>3, 3, df_fake['Wine'])\n",
    "df_fake.head()"
   ]
  },
  {
   "source": [
    "The deep_tabular_augmentation library has another method in its sleeve: predict_with_noise. What this does is the following, sampling from a normal distribution each element (independend of each other element) will be multiplied by 1 plus the sampled number. Why should we do this? The answer is that the Variational Autoencoder works similar to a PCA, resulting in sharper defined relations between variables. So the Variational Autoencoder keeps mean and standard deviance within the variables, however, the trained parameters of the model already find out \"hidden\" relations between variables. When these relations are linear the Variational Autoencoder de facto performs a PCA. We'll have a look at it in a second."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Wine    Alcohol  Malic.acid       Ash        Acl          Mg   Phenols  \\\n",
       "0     2  12.106316    2.142077  2.127616  19.408381   92.179733  2.418110   \n",
       "1     2  12.147018    2.009001  2.188961  22.396885  101.379967  2.318827   \n",
       "2     2  13.262069    1.864855  2.277317  19.010958   95.259872  2.493481   \n",
       "3     2  13.586826    2.270907  2.191374  22.129240   91.323662  1.793574   \n",
       "4     2  13.825186    1.984307  2.333792  18.083511  102.420219  2.705270   \n",
       "\n",
       "   Flavanoids  Nonflavanoid.phenols   Proanth  Color.int       Hue        OD  \\\n",
       "0    2.124110              0.353460  1.544483   3.348948  1.057455  2.828610   \n",
       "1    2.177448              0.336155  1.584168   3.603321  0.984947  2.718268   \n",
       "2    2.209520              0.347245  1.750477   3.704191  0.989856  2.743370   \n",
       "3    1.240703              0.437917  1.393128   3.973017  0.862660  2.276499   \n",
       "4    2.401335              0.312623  1.910688   4.119694  1.008278  3.032777   \n",
       "\n",
       "      Proline  \n",
       "0  560.824158  \n",
       "1  604.860901  \n",
       "2  631.236572  \n",
       "3  543.781311  \n",
       "4  685.976562  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Wine</th>\n      <th>Alcohol</th>\n      <th>Malic.acid</th>\n      <th>Ash</th>\n      <th>Acl</th>\n      <th>Mg</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid.phenols</th>\n      <th>Proanth</th>\n      <th>Color.int</th>\n      <th>Hue</th>\n      <th>OD</th>\n      <th>Proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>12.106316</td>\n      <td>2.142077</td>\n      <td>2.127616</td>\n      <td>19.408381</td>\n      <td>92.179733</td>\n      <td>2.418110</td>\n      <td>2.124110</td>\n      <td>0.353460</td>\n      <td>1.544483</td>\n      <td>3.348948</td>\n      <td>1.057455</td>\n      <td>2.828610</td>\n      <td>560.824158</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>12.147018</td>\n      <td>2.009001</td>\n      <td>2.188961</td>\n      <td>22.396885</td>\n      <td>101.379967</td>\n      <td>2.318827</td>\n      <td>2.177448</td>\n      <td>0.336155</td>\n      <td>1.584168</td>\n      <td>3.603321</td>\n      <td>0.984947</td>\n      <td>2.718268</td>\n      <td>604.860901</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>13.262069</td>\n      <td>1.864855</td>\n      <td>2.277317</td>\n      <td>19.010958</td>\n      <td>95.259872</td>\n      <td>2.493481</td>\n      <td>2.209520</td>\n      <td>0.347245</td>\n      <td>1.750477</td>\n      <td>3.704191</td>\n      <td>0.989856</td>\n      <td>2.743370</td>\n      <td>631.236572</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>13.586826</td>\n      <td>2.270907</td>\n      <td>2.191374</td>\n      <td>22.129240</td>\n      <td>91.323662</td>\n      <td>1.793574</td>\n      <td>1.240703</td>\n      <td>0.437917</td>\n      <td>1.393128</td>\n      <td>3.973017</td>\n      <td>0.862660</td>\n      <td>2.276499</td>\n      <td>543.781311</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>13.825186</td>\n      <td>1.984307</td>\n      <td>2.333792</td>\n      <td>18.083511</td>\n      <td>102.420219</td>\n      <td>2.705270</td>\n      <td>2.401335</td>\n      <td>0.312623</td>\n      <td>1.910688</td>\n      <td>4.119694</td>\n      <td>1.008278</td>\n      <td>3.032777</td>\n      <td>685.976562</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "df_fake_with_noise = autoenc_model_fit.predict_with_noise(no_samples=500, scaler=scaler, cols=cols, mu=0, sigma=0.05, group_var='Wine')\n",
    "df_fake_with_noise['Wine'] = np.round(df_fake_with_noise['Wine']).astype(int)\n",
    "df_fake_with_noise['Wine'] = np.where(df_fake_with_noise['Wine']<1, 1, df_fake_with_noise['Wine'])\n",
    "df_fake_with_noise['Wine'] = np.where(df_fake_with_noise['Wine']>3, 3, df_fake_with_noise['Wine'])\n",
    "df_fake_with_noise.head()"
   ]
  },
  {
   "source": [
    "Let's have a look at the descriptives, especially the mean. Can you spot a difference between the real and the fake data?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Alcohol Malic.acid       Ash        Acl          Mg   Phenols  \\\n",
       "           mean       mean      mean       mean        mean      mean   \n",
       "Wine                                                                    \n",
       "1     13.744746   2.010678  2.455593  17.037288  106.338983  2.840169   \n",
       "2     12.278732   1.932676  2.244789  20.238028   94.549296  2.258873   \n",
       "3     13.153750   3.333750  2.437083  21.416667   99.312500  1.678750   \n",
       "\n",
       "     Flavanoids Nonflavanoid.phenols   Proanth Color.int       Hue        OD  \\\n",
       "           mean                 mean      mean      mean      mean      mean   \n",
       "Wine                                                                           \n",
       "1      2.982373             0.290000  1.899322  5.528305  1.062034  3.157797   \n",
       "2      2.080845             0.363662  1.630282  3.086620  1.056282  2.785352   \n",
       "3      0.781458             0.447500  1.153542  7.396250  0.682708  1.683542   \n",
       "\n",
       "          Proline  \n",
       "             mean  \n",
       "Wine               \n",
       "1     1115.711864  \n",
       "2      519.507042  \n",
       "3      629.895833  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Alcohol</th>\n      <th>Malic.acid</th>\n      <th>Ash</th>\n      <th>Acl</th>\n      <th>Mg</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid.phenols</th>\n      <th>Proanth</th>\n      <th>Color.int</th>\n      <th>Hue</th>\n      <th>OD</th>\n      <th>Proline</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n    </tr>\n    <tr>\n      <th>Wine</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>13.744746</td>\n      <td>2.010678</td>\n      <td>2.455593</td>\n      <td>17.037288</td>\n      <td>106.338983</td>\n      <td>2.840169</td>\n      <td>2.982373</td>\n      <td>0.290000</td>\n      <td>1.899322</td>\n      <td>5.528305</td>\n      <td>1.062034</td>\n      <td>3.157797</td>\n      <td>1115.711864</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.278732</td>\n      <td>1.932676</td>\n      <td>2.244789</td>\n      <td>20.238028</td>\n      <td>94.549296</td>\n      <td>2.258873</td>\n      <td>2.080845</td>\n      <td>0.363662</td>\n      <td>1.630282</td>\n      <td>3.086620</td>\n      <td>1.056282</td>\n      <td>2.785352</td>\n      <td>519.507042</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13.153750</td>\n      <td>3.333750</td>\n      <td>2.437083</td>\n      <td>21.416667</td>\n      <td>99.312500</td>\n      <td>1.678750</td>\n      <td>0.781458</td>\n      <td>0.447500</td>\n      <td>1.153542</td>\n      <td>7.396250</td>\n      <td>0.682708</td>\n      <td>1.683542</td>\n      <td>629.895833</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "df.groupby('Wine').describe().loc[:,(slice(None),['mean'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Alcohol Malic.acid       Ash        Acl          Mg   Phenols  \\\n",
       "           mean       mean      mean       mean        mean      mean   \n",
       "Wine                                                                    \n",
       "1     13.756567   1.972927  2.439609  16.679155  110.221558  2.888496   \n",
       "2     12.550643   2.169043  2.292549  19.789505   96.663307  2.250596   \n",
       "3     13.225099   3.809655  2.512825  22.554857  101.781906  1.470288   \n",
       "\n",
       "     Flavanoids Nonflavanoid.phenols   Proanth Color.int       Hue        OD  \\\n",
       "           mean                 mean      mean      mean      mean      mean   \n",
       "Wine                                                                           \n",
       "1      2.933521             0.296994  1.980520  5.707772  1.065832  3.040885   \n",
       "2      2.012712             0.350111  1.627728  3.967775  1.007894  2.744052   \n",
       "3      0.664501             0.507955  0.921151  7.329511  0.642636  1.483876   \n",
       "\n",
       "          Proline  \n",
       "             mean  \n",
       "Wine               \n",
       "1     1103.145508  \n",
       "2      616.919006  \n",
       "3      621.194458  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Alcohol</th>\n      <th>Malic.acid</th>\n      <th>Ash</th>\n      <th>Acl</th>\n      <th>Mg</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid.phenols</th>\n      <th>Proanth</th>\n      <th>Color.int</th>\n      <th>Hue</th>\n      <th>OD</th>\n      <th>Proline</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n    </tr>\n    <tr>\n      <th>Wine</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>13.756567</td>\n      <td>1.972927</td>\n      <td>2.439609</td>\n      <td>16.679155</td>\n      <td>110.221558</td>\n      <td>2.888496</td>\n      <td>2.933521</td>\n      <td>0.296994</td>\n      <td>1.980520</td>\n      <td>5.707772</td>\n      <td>1.065832</td>\n      <td>3.040885</td>\n      <td>1103.145508</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.550643</td>\n      <td>2.169043</td>\n      <td>2.292549</td>\n      <td>19.789505</td>\n      <td>96.663307</td>\n      <td>2.250596</td>\n      <td>2.012712</td>\n      <td>0.350111</td>\n      <td>1.627728</td>\n      <td>3.967775</td>\n      <td>1.007894</td>\n      <td>2.744052</td>\n      <td>616.919006</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13.225099</td>\n      <td>3.809655</td>\n      <td>2.512825</td>\n      <td>22.554857</td>\n      <td>101.781906</td>\n      <td>1.470288</td>\n      <td>0.664501</td>\n      <td>0.507955</td>\n      <td>0.921151</td>\n      <td>7.329511</td>\n      <td>0.642636</td>\n      <td>1.483876</td>\n      <td>621.194458</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "df_fake.groupby('Wine').describe().loc[:,(slice(None),['mean'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Alcohol Malic.acid       Ash        Acl          Mg   Phenols  \\\n",
       "           mean       mean      mean       mean        mean      mean   \n",
       "Wine                                                                    \n",
       "1     13.816388   1.980611  2.445411  16.888805  109.618469  2.890874   \n",
       "2     12.554925   2.182181  2.296422  19.779770   96.850357  2.270568   \n",
       "3     13.099731   3.869962  2.526824  22.768381  102.265625  1.440060   \n",
       "\n",
       "     Flavanoids Nonflavanoid.phenols   Proanth Color.int       Hue        OD  \\\n",
       "           mean                 mean      mean      mean      mean      mean   \n",
       "Wine                                                                           \n",
       "1      2.916224             0.297376  1.960559  5.643065  1.068307  3.012105   \n",
       "2      2.013577             0.349725  1.625649  4.029018  1.005889  2.740945   \n",
       "3      0.597155             0.517642  0.879244  7.493037  0.621761  1.406803   \n",
       "\n",
       "          Proline  \n",
       "             mean  \n",
       "Wine               \n",
       "1     1106.231079  \n",
       "2      626.561035  \n",
       "3      605.561829  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Alcohol</th>\n      <th>Malic.acid</th>\n      <th>Ash</th>\n      <th>Acl</th>\n      <th>Mg</th>\n      <th>Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid.phenols</th>\n      <th>Proanth</th>\n      <th>Color.int</th>\n      <th>Hue</th>\n      <th>OD</th>\n      <th>Proline</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n      <th>mean</th>\n    </tr>\n    <tr>\n      <th>Wine</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>13.816388</td>\n      <td>1.980611</td>\n      <td>2.445411</td>\n      <td>16.888805</td>\n      <td>109.618469</td>\n      <td>2.890874</td>\n      <td>2.916224</td>\n      <td>0.297376</td>\n      <td>1.960559</td>\n      <td>5.643065</td>\n      <td>1.068307</td>\n      <td>3.012105</td>\n      <td>1106.231079</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.554925</td>\n      <td>2.182181</td>\n      <td>2.296422</td>\n      <td>19.779770</td>\n      <td>96.850357</td>\n      <td>2.270568</td>\n      <td>2.013577</td>\n      <td>0.349725</td>\n      <td>1.625649</td>\n      <td>4.029018</td>\n      <td>1.005889</td>\n      <td>2.740945</td>\n      <td>626.561035</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13.099731</td>\n      <td>3.869962</td>\n      <td>2.526824</td>\n      <td>22.768381</td>\n      <td>102.265625</td>\n      <td>1.440060</td>\n      <td>0.597155</td>\n      <td>0.517642</td>\n      <td>0.879244</td>\n      <td>7.493037</td>\n      <td>0.621761</td>\n      <td>1.406803</td>\n      <td>605.561829</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "df_fake_with_noise.groupby('Wine').describe().loc[:,(slice(None),['mean'])]"
   ]
  },
  {
   "source": [
    "Now let's have a graphic look on how the fake data looks vs the real data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/alcohol_vs_hue_3.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This is what I meant by \"performing a PCA\". One can clearly see how the Variational Autoencoder gave structure to the relation of Alcohol and Hue. If we add noise to it, this relation vanishes. But what happens, if we use more than 3 latent factors? This is the result with 14 (=input variables) latent factors:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/alcohol_vs_hue_14.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The same pattern emerges. However, when applying random noise to it, the resulting data looks pretty much like the real data.\n",
    "\n",
    "Now let's have a look at some distributions. The first image always represents the results with 3 latent factors, the second one with 14 latent factors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3 latent factors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/alcohol_dist_3.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 14 latent factors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/alcohol_dist_14.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3 latent factors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/color_int_dist_3.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 14 latent factors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/color_int_dist_14.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3 latent factors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/flavanoids_dist_3.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 14 latent factors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![alt text](Images/DeepLearningDataAugmentation/flavanoids_dist_14.PNG)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We see that when using a Variational Autoencoder to make data augmentation on tabular data, it actually already finds relations between variables. If we want to get rid of this effect and add random noise to the data, the resulting distributions look pretty much like the original, real data points. How can we use these insights to improve machine learning/deep learning models? This I will cover in an upcoming blogpost.\n",
    "\n",
    "Until then, stay tuned for more!\n",
    "Lasse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}