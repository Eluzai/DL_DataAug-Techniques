{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasse's book recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would Lasse rate this book?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the third part of my little project to build a rating system on text which we extract from images and which in turn leads to a rating on how much I will like this book. In this notebook I want to show you how to make use of ipywidgets to make a notebook which we can use as a web appplication. Furthermore, I will show you how to download the trained model from [part 2] (https://lschmiddey.github.io/fastpages_/2020/09/26/Use-pretrained-Bert-model-for-classification.html) from my private GoogleDrive. So let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googledrivedownloader in /opt/conda/envs/fastai/lib/python3.8/site-packages (0.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install googledrivedownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "from PIL import Image, ImageFilter \n",
    "import pytesseract\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from pathlib import Path\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many deep learning models are huge, so we cannot upload them into our git repository. I put my pretrained model in my GoogleDrive and made it publically available. So let's download the model form there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1kk_SvwpwZeuLnZirW5vbrd8FEnm7yJRt',\n",
    "                                    dest_path='./export.pkl',\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take all the functionality I already showed you in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_img(input_img):\n",
    "    \n",
    "    img = input_img.rotate(angle=270, resample=0, expand=10, center=None, translate=None, fillcolor=None)\n",
    "    img = img.filter(ImageFilter.MedianFilter)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(img):\n",
    "    return pytesseract.image_to_string(img, lang=\"deu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pattern(text):\n",
    "    return pattern.sub(lambda m: rep[re.escape(m.group(0))], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = {\"\\n\": \"\", \"`\": \"\", '%':\"\", '°': '', '&':'', '‘':'', '€':'e', '®':'', '\\\\': '', '5':'s', '1':'i', '_':'', '-':''} # define desired replacements here\n",
    "\n",
    "# use these three lines to do the replacement\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "#Python 3 renamed dict.iteritems to dict.items so use rep.items() for latest versions\n",
    "pattern = re.compile(\"|\".join(rep.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "def tokenize_text(sent):\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation=True,\n",
    "                        max_length = 256,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        #padding='longest',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(text):\n",
    "    \n",
    "    input_ids, attention_masks = tokenize_text(text)\n",
    "    dataset = TensorDataset(input_ids, attention_masks)\n",
    "    batch_size = 1\n",
    "    app_dataloader = DataLoader(\n",
    "                dataset, # The validation samples.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    return app_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we create a predict function, which takes the tokenized input and uses the downloaded model to make a prediction how much I will like this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader):\n",
    "    # Prediction on test set\n",
    "    device = torch.device('cpu')\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions = []\n",
    "\n",
    "    # Predict \n",
    "    for batch in dataloader:\n",
    "\n",
    "            # Add batch to CPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask = batch\n",
    "\n",
    "            # Telling the model not to compute or store gradients, saving memory and \n",
    "            # speeding up prediction\n",
    "            with torch.no_grad():\n",
    "              # Forward pass, calculate logit predictions\n",
    "              outputs = model(b_input_ids, token_type_ids=None, \n",
    "                              attention_mask=b_input_mask)\n",
    "\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            predictions.append(logits)\n",
    "            \n",
    "            return np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-german-cased'\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', PRE_TRAINED_MODEL_NAME)    # Download vocabulary from S3 and cache.\n",
    "n_classes=5\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-german-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = n_classes, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we trained our model on our GPU, we want to make the predictions on the CPU. So let's load the model onto our CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.load_state_dict(torch.load(p/'export.pkl', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use all this and put it in a ipython widget. So in the end we will interactively be able to upload images from our device and get a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "out_pl = widgets.Output()\n",
    "rating_widget = widgets.Label()\n",
    "btn_run = widgets.Button(description='Lasses recommendation:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_text(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(proc_img(img).to_thumb(256,256))\n",
    "    text = use_pattern(get_text(proc_img(img)))\n",
    "    star_rating = predict(create_dataloader(text))\n",
    "    rating_widget.value = f'Lasse would rate this book with {star_rating+1} star(s) out of 5 stars!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run.on_click(on_click_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec83fb72de15438e9a82debe9cb68f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Upload image'), FileUpload(value={}, description='Upload'), Button(description='La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([widgets.Label('Upload image'),\n",
    "     btn_upload, btn_run, out_pl, rating_widget])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! That worked like a charme! Next, I will try to use voila and binder to create a web app from this notebook. So stay tuned!\n",
    "\n",
    "Lasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
